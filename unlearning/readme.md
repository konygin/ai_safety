* [Liu et al. - Towards Safer Large Language Models through Machine Unlearning 2024](https://arxiv.org/abs/2402.10058)
  1. guided distortion: aims to facilitate the original LLM to respond accurately to harmful prompts
  2. random disassociation: infuses randomness into the modelâ€™s learning process, which is essential for disrupting the direct association between harmful prompts and their corresponding harmful responses
  3. preservation divergence: unlearning harmful knowledge does not jeopardize responses to non-harmful prompts
  4. knowledge negation
