# Unlearning

- [Liu et al. - Towards Safer Large Language Models through Machine Unlearning 2024](https://arxiv.org/abs/2402.10058)
  - guided distortion: aims to facilitate the original LLM to respond accurately to harmful prompts
  - random disassociation: infuses randomness into the modelâ€™s learning process, which is essential for disrupting the direct association between harmful prompts and their corresponding harmful responses
  - preservation divergence: unlearning harmful knowledge does not jeopardize responses to non-harmful prompts
  - knowledge negation
